{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcfef6b-649e-4c3a-949e-a6e2da94e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2839c08-8397-4cfc-8e3c-08a0a3720bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>517×13 DataFrame</span></div><div style = \"float: right; font-style: italic;\"><span>492 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">X</th><th style = \"text-align: left;\">Y</th><th style = \"text-align: left;\">month</th><th style = \"text-align: left;\">day</th><th style = \"text-align: left;\">FFMC</th><th style = \"text-align: left;\">DMC</th><th style = \"text-align: left;\">DC</th><th style = \"text-align: left;\">ISI</th><th style = \"text-align: left;\">temp</th><th style = \"text-align: left;\">RH</th><th style = \"text-align: left;\">wind</th><th style = \"text-align: left;\">rain</th><th style = \"text-align: left;\">area</th></tr><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">mar</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">86.2</td><td style = \"text-align: right;\">26.2</td><td style = \"text-align: right;\">94.3</td><td style = \"text-align: right;\">5.1</td><td style = \"text-align: right;\">8.2</td><td style = \"text-align: right;\">51</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">oct</td><td style = \"text-align: left;\">tue</td><td style = \"text-align: right;\">90.6</td><td style = \"text-align: right;\">35.4</td><td style = \"text-align: right;\">669.1</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">18.0</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">0.9</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">oct</td><td style = \"text-align: left;\">sat</td><td style = \"text-align: right;\">90.6</td><td style = \"text-align: right;\">43.7</td><td style = \"text-align: right;\">686.9</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">14.6</td><td style = \"text-align: right;\">33</td><td style = \"text-align: right;\">1.3</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">mar</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">91.7</td><td style = \"text-align: right;\">33.3</td><td style = \"text-align: right;\">77.5</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">8.3</td><td style = \"text-align: right;\">97</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">mar</td><td style = \"text-align: left;\">sun</td><td style = \"text-align: right;\">89.3</td><td style = \"text-align: right;\">51.3</td><td style = \"text-align: right;\">102.2</td><td style = \"text-align: right;\">9.6</td><td style = \"text-align: right;\">11.4</td><td style = \"text-align: right;\">99</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">sun</td><td style = \"text-align: right;\">92.3</td><td style = \"text-align: right;\">85.3</td><td style = \"text-align: right;\">488.0</td><td style = \"text-align: right;\">14.7</td><td style = \"text-align: right;\">22.2</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">mon</td><td style = \"text-align: right;\">92.3</td><td style = \"text-align: right;\">88.9</td><td style = \"text-align: right;\">495.6</td><td style = \"text-align: right;\">8.5</td><td style = \"text-align: right;\">24.1</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">mon</td><td style = \"text-align: right;\">91.5</td><td style = \"text-align: right;\">145.4</td><td style = \"text-align: right;\">608.2</td><td style = \"text-align: right;\">10.7</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">86</td><td style = \"text-align: right;\">2.2</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">sep</td><td style = \"text-align: left;\">tue</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">129.5</td><td style = \"text-align: right;\">692.6</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">13.1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">sep</td><td style = \"text-align: left;\">sat</td><td style = \"text-align: right;\">92.5</td><td style = \"text-align: right;\">88.0</td><td style = \"text-align: right;\">698.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">22.8</td><td style = \"text-align: right;\">40</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">sep</td><td style = \"text-align: left;\">sat</td><td style = \"text-align: right;\">92.5</td><td style = \"text-align: right;\">88.0</td><td style = \"text-align: right;\">698.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">17.8</td><td style = \"text-align: right;\">51</td><td style = \"text-align: right;\">7.2</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">sep</td><td style = \"text-align: left;\">sat</td><td style = \"text-align: right;\">92.8</td><td style = \"text-align: right;\">73.2</td><td style = \"text-align: right;\">713.0</td><td style = \"text-align: right;\">22.6</td><td style = \"text-align: right;\">19.3</td><td style = \"text-align: right;\">38</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">63.5</td><td style = \"text-align: right;\">70.8</td><td style = \"text-align: right;\">665.3</td><td style = \"text-align: right;\">0.8</td><td style = \"text-align: right;\">17.0</td><td style = \"text-align: right;\">72</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: left;\">&vellip;</td><td style = \"text-align: left;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">506</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">thu</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">163.2</td><td style = \"text-align: right;\">744.4</td><td style = \"text-align: right;\">10.1</td><td style = \"text-align: right;\">26.7</td><td style = \"text-align: right;\">35</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">5.8</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">507</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">166.9</td><td style = \"text-align: right;\">752.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">18.5</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">8.5</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">508</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">166.9</td><td style = \"text-align: right;\">752.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">25.9</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">3.6</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">509</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">166.9</td><td style = \"text-align: right;\">752.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">25.9</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">3.6</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">510</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">166.9</td><td style = \"text-align: right;\">752.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">21.1</td><td style = \"text-align: right;\">71</td><td style = \"text-align: right;\">7.6</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">2.17</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">511</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">fri</td><td style = \"text-align: right;\">91.0</td><td style = \"text-align: right;\">166.9</td><td style = \"text-align: right;\">752.6</td><td style = \"text-align: right;\">7.1</td><td style = \"text-align: right;\">18.2</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.43</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">512</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">sun</td><td style = \"text-align: right;\">81.6</td><td style = \"text-align: right;\">56.7</td><td style = \"text-align: right;\">665.6</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: right;\">27.8</td><td style = \"text-align: right;\">35</td><td style = \"text-align: right;\">2.7</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">513</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">sun</td><td style = \"text-align: right;\">81.6</td><td style = \"text-align: right;\">56.7</td><td style = \"text-align: right;\">665.6</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: right;\">27.8</td><td style = \"text-align: right;\">32</td><td style = \"text-align: right;\">2.7</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">6.44</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">514</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">sun</td><td style = \"text-align: right;\">81.6</td><td style = \"text-align: right;\">56.7</td><td style = \"text-align: right;\">665.6</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: right;\">21.9</td><td style = \"text-align: right;\">71</td><td style = \"text-align: right;\">5.8</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">54.29</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">515</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">sun</td><td style = \"text-align: right;\">81.6</td><td style = \"text-align: right;\">56.7</td><td style = \"text-align: right;\">665.6</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: right;\">21.2</td><td style = \"text-align: right;\">70</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">11.16</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">516</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">aug</td><td style = \"text-align: left;\">sat</td><td style = \"text-align: right;\">94.4</td><td style = \"text-align: right;\">146.0</td><td style = \"text-align: right;\">614.7</td><td style = \"text-align: right;\">11.3</td><td style = \"text-align: right;\">25.6</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">517</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">nov</td><td style = \"text-align: left;\">tue</td><td style = \"text-align: right;\">79.5</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">106.7</td><td style = \"text-align: right;\">1.1</td><td style = \"text-align: right;\">11.8</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">4.5</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& X & Y & month & day & FFMC & DMC & DC & ISI & temp & RH & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & String3 & String3 & Float64 & Float64 & Float64 & Float64 & Float64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 7 & 5 & mar & fri & 86.2 & 26.2 & 94.3 & 5.1 & 8.2 & 51 & $\\dots$ \\\\\n",
       "\t2 & 7 & 4 & oct & tue & 90.6 & 35.4 & 669.1 & 6.7 & 18.0 & 33 & $\\dots$ \\\\\n",
       "\t3 & 7 & 4 & oct & sat & 90.6 & 43.7 & 686.9 & 6.7 & 14.6 & 33 & $\\dots$ \\\\\n",
       "\t4 & 8 & 6 & mar & fri & 91.7 & 33.3 & 77.5 & 9.0 & 8.3 & 97 & $\\dots$ \\\\\n",
       "\t5 & 8 & 6 & mar & sun & 89.3 & 51.3 & 102.2 & 9.6 & 11.4 & 99 & $\\dots$ \\\\\n",
       "\t6 & 8 & 6 & aug & sun & 92.3 & 85.3 & 488.0 & 14.7 & 22.2 & 29 & $\\dots$ \\\\\n",
       "\t7 & 8 & 6 & aug & mon & 92.3 & 88.9 & 495.6 & 8.5 & 24.1 & 27 & $\\dots$ \\\\\n",
       "\t8 & 8 & 6 & aug & mon & 91.5 & 145.4 & 608.2 & 10.7 & 8.0 & 86 & $\\dots$ \\\\\n",
       "\t9 & 8 & 6 & sep & tue & 91.0 & 129.5 & 692.6 & 7.0 & 13.1 & 63 & $\\dots$ \\\\\n",
       "\t10 & 7 & 5 & sep & sat & 92.5 & 88.0 & 698.6 & 7.1 & 22.8 & 40 & $\\dots$ \\\\\n",
       "\t11 & 7 & 5 & sep & sat & 92.5 & 88.0 & 698.6 & 7.1 & 17.8 & 51 & $\\dots$ \\\\\n",
       "\t12 & 7 & 5 & sep & sat & 92.8 & 73.2 & 713.0 & 22.6 & 19.3 & 38 & $\\dots$ \\\\\n",
       "\t13 & 6 & 5 & aug & fri & 63.5 & 70.8 & 665.3 & 0.8 & 17.0 & 72 & $\\dots$ \\\\\n",
       "\t14 & 6 & 5 & sep & mon & 90.9 & 126.5 & 686.5 & 7.0 & 21.3 & 42 & $\\dots$ \\\\\n",
       "\t15 & 6 & 5 & sep & wed & 92.9 & 133.3 & 699.6 & 9.2 & 26.4 & 21 & $\\dots$ \\\\\n",
       "\t16 & 6 & 5 & sep & fri & 93.3 & 141.2 & 713.9 & 13.9 & 22.9 & 44 & $\\dots$ \\\\\n",
       "\t17 & 5 & 5 & mar & sat & 91.7 & 35.8 & 80.8 & 7.8 & 15.1 & 27 & $\\dots$ \\\\\n",
       "\t18 & 8 & 5 & oct & mon & 84.9 & 32.8 & 664.2 & 3.0 & 16.7 & 47 & $\\dots$ \\\\\n",
       "\t19 & 6 & 4 & mar & wed & 89.2 & 27.9 & 70.8 & 6.3 & 15.9 & 35 & $\\dots$ \\\\\n",
       "\t20 & 6 & 4 & apr & sat & 86.3 & 27.4 & 97.1 & 5.1 & 9.3 & 44 & $\\dots$ \\\\\n",
       "\t21 & 6 & 4 & sep & tue & 91.0 & 129.5 & 692.6 & 7.0 & 18.3 & 40 & $\\dots$ \\\\\n",
       "\t22 & 5 & 4 & sep & mon & 91.8 & 78.5 & 724.3 & 9.2 & 19.1 & 38 & $\\dots$ \\\\\n",
       "\t23 & 7 & 4 & jun & sun & 94.3 & 96.3 & 200.0 & 56.1 & 21.0 & 44 & $\\dots$ \\\\\n",
       "\t24 & 7 & 4 & aug & sat & 90.2 & 110.9 & 537.4 & 6.2 & 19.5 & 43 & $\\dots$ \\\\\n",
       "\t25 & 7 & 4 & aug & sat & 93.5 & 139.4 & 594.2 & 20.3 & 23.7 & 32 & $\\dots$ \\\\\n",
       "\t26 & 7 & 4 & aug & sun & 91.4 & 142.4 & 601.4 & 10.6 & 16.3 & 60 & $\\dots$ \\\\\n",
       "\t27 & 7 & 4 & sep & fri & 92.4 & 117.9 & 668.0 & 12.2 & 19.0 & 34 & $\\dots$ \\\\\n",
       "\t28 & 7 & 4 & sep & mon & 90.9 & 126.5 & 686.5 & 7.0 & 19.4 & 48 & $\\dots$ \\\\\n",
       "\t29 & 6 & 3 & sep & sat & 93.4 & 145.4 & 721.4 & 8.1 & 30.2 & 24 & $\\dots$ \\\\\n",
       "\t30 & 6 & 3 & sep & sun & 93.5 & 149.3 & 728.6 & 8.1 & 22.8 & 39 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m517×13 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m X     \u001b[0m\u001b[1m Y     \u001b[0m\u001b[1m month   \u001b[0m\u001b[1m day     \u001b[0m\u001b[1m FFMC    \u001b[0m\u001b[1m DMC     \u001b[0m\u001b[1m DC      \u001b[0m\u001b[1m ISI     \u001b[0m\u001b[1m tem\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m String3 \u001b[0m\u001b[90m String3 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     7      5  mar      fri         86.2     26.2     94.3      5.1      ⋯\n",
       "   2 │     7      4  oct      tue         90.6     35.4    669.1      6.7\n",
       "   3 │     7      4  oct      sat         90.6     43.7    686.9      6.7\n",
       "   4 │     8      6  mar      fri         91.7     33.3     77.5      9.0\n",
       "   5 │     8      6  mar      sun         89.3     51.3    102.2      9.6      ⋯\n",
       "   6 │     8      6  aug      sun         92.3     85.3    488.0     14.7\n",
       "   7 │     8      6  aug      mon         92.3     88.9    495.6      8.5\n",
       "   8 │     8      6  aug      mon         91.5    145.4    608.2     10.7\n",
       "   9 │     8      6  sep      tue         91.0    129.5    692.6      7.0      ⋯\n",
       "  10 │     7      5  sep      sat         92.5     88.0    698.6      7.1\n",
       "  11 │     7      5  sep      sat         92.5     88.0    698.6      7.1\n",
       "  ⋮  │   ⋮      ⋮       ⋮        ⋮        ⋮        ⋮        ⋮        ⋮         ⋱\n",
       " 508 │     2      4  aug      fri         91.0    166.9    752.6      7.1\n",
       " 509 │     1      2  aug      fri         91.0    166.9    752.6      7.1      ⋯\n",
       " 510 │     5      4  aug      fri         91.0    166.9    752.6      7.1\n",
       " 511 │     6      5  aug      fri         91.0    166.9    752.6      7.1\n",
       " 512 │     8      6  aug      sun         81.6     56.7    665.6      1.9\n",
       " 513 │     4      3  aug      sun         81.6     56.7    665.6      1.9      ⋯\n",
       " 514 │     2      4  aug      sun         81.6     56.7    665.6      1.9\n",
       " 515 │     7      4  aug      sun         81.6     56.7    665.6      1.9\n",
       " 516 │     1      4  aug      sat         94.4    146.0    614.7     11.3\n",
       " 517 │     6      3  nov      tue         79.5      3.0    106.7      1.1      ⋯\n",
       "\u001b[36m                                                  5 columns and 496 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_fires = CSV.read(\"./data/forestfires.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7342d0b9-7167-4f36-9331-bb489a1fe65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CategoricalArrays\n",
    "\n",
    "function load_dataset(Y_name)\n",
    "    # Loading and preprocessing\n",
    "    forest_fires = CSV.read(\"./data/forestfires.csv\", DataFrame)\n",
    "    forest_fires.month = levelcode.(CategoricalArray(forest_fires.month))\n",
    "    forest_fires.day = levelcode.(CategoricalArray(forest_fires.day))\n",
    "    forest_fires = mapcols(col -> Float32.(col), forest_fires)\n",
    "\n",
    "    # Getting X and Y\n",
    "    X = select(forest_fires, Not(Y_name))\n",
    "    Y = select(forest_fires, Y_name)\n",
    "    return Matrix(X)', Matrix(Y)'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcff993d-47b0-4fd3-9a93-470021d29db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[7.0 7.0 … 1.0 6.0; 5.0 4.0 … 4.0 3.0; … ; 6.7 0.9 … 4.0 4.5; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = load_dataset(:rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939a6566-59bd-41c7-bbe9-b0895533bd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[6.0 4.0 … 3.0 2.0; 3.0 4.0 … 4.0 2.0; … ; 2.7 4.5 … 4.5 0.9; 0.0 88.49 … 0.0 6.84], Float32[0.0 0.0 … 0.0 0.0], Float32[3.0 1.0 … 1.0 3.0; 5.0 5.0 … 4.0 4.0; … ; 2.7 2.2 … 4.9 1.8; 2.18 7.3 … 9.71 0.0], Float32[0.0 0.0 … 0.0 0.0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Mlyn\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430eb4ac-1446-4f60-a59b-6454036f20a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizerSGD(0.01f0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Mlyn\n",
    "\n",
    "model = create_model(regression, [\n",
    "    BlueprintLinear(12, 5, method_xavier_normal),\n",
    "    BlueprintActivation(method_sigmoid),\n",
    "    BlueprintLinear(5, 3, method_xavier_normal),\n",
    "    BlueprintActivation(method_sigmoid),\n",
    "    BlueprintLinear(3, 1, method_xavier_normal),\n",
    "    BlueprintActivation(method_sigmoid)\n",
    "])\n",
    "\n",
    "optimizer = OptimizerSGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e82df4-54fd-4d60-b195-307368e87724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 1] Test loss = 0.09115090128485129; Learning loss = 0.36622094991460613\n",
      "[EPOCH 2] Test loss = 0.08996068890482693; Learning loss = 0.12789663877393945\n",
      "[EPOCH 3] Test loss = 0.08879031412510979; Learning loss = 0.12616387326311368\n",
      "[EPOCH 4] Test loss = 0.08773026700433703; Learning loss = 0.13160330548186927\n",
      "[EPOCH 5] Test loss = 0.08660407769125822; Learning loss = 0.12386653155873917\n",
      "[EPOCH 6] Test loss = 0.08549004086443723; Learning loss = 0.12319099666359097\n",
      "[EPOCH 7] Test loss = 0.084395124276685; Learning loss = 0.1217722164031519\n",
      "[EPOCH 8] Test loss = 0.08331770844748844; Learning loss = 0.12130304122333724\n",
      "[EPOCH 9] Test loss = 0.08249443308389146; Learning loss = 0.359613902919245\n",
      "[EPOCH 10] Test loss = 0.08148651740749703; Learning loss = 0.12060151198609792\n",
      "[EPOCH 11] Test loss = 0.08046633044511818; Learning loss = 0.11742473502247211\n",
      "[EPOCH 12] Test loss = 0.07945410223579516; Learning loss = 0.11719448224807334\n",
      "[EPOCH 13] Test loss = 0.07849522906683117; Learning loss = 0.11774815231376226\n",
      "[EPOCH 14] Test loss = 0.07751948422974689; Learning loss = 0.11526502643581245\n",
      "[EPOCH 15] Test loss = 0.07656051453870803; Learning loss = 0.11432791415385005\n",
      "[EPOCH 16] Test loss = 0.07561816872384673; Learning loss = 0.11321060686943592\n",
      "[EPOCH 17] Test loss = 0.0746919036175375; Learning loss = 0.11240692506058206\n",
      "[EPOCH 18] Test loss = 0.07377934070221664; Learning loss = 0.11206937818109461\n",
      "[EPOCH 19] Test loss = 0.07288458339381206; Learning loss = 0.11064643599317432\n",
      "[EPOCH 20] Test loss = 0.07200389563865689; Learning loss = 0.11016999222358428\n",
      "[EPOCH 21] Test loss = 0.07113824927380391; Learning loss = 0.10952571480133151\n",
      "[EPOCH 22] Test loss = 0.07030071650520942; Learning loss = 0.10763726009886994\n",
      "[EPOCH 23] Test loss = 0.06946523042363552; Learning loss = 0.1074569307026643\n",
      "[EPOCH 24] Test loss = 0.06864045230353776; Learning loss = 0.10676514941711948\n",
      "[EPOCH 25] Test loss = 0.06787630814583388; Learning loss = 0.11212128424879775\n",
      "[EPOCH 26] Test loss = 0.06708043127067446; Learning loss = 0.10522971678615958\n",
      "[EPOCH 27] Test loss = 0.06629939640358942; Learning loss = 0.10447313773885661\n",
      "[EPOCH 28] Test loss = 0.06553123185039673; Learning loss = 0.1039281952981349\n",
      "[EPOCH 29] Test loss = 0.06477743811691423; Learning loss = 0.1027549864694404\n",
      "[EPOCH 30] Test loss = 0.06403246813542073; Learning loss = 0.10268325967232679\n",
      "[EPOCH 31] Test loss = 0.06330314896797073; Learning loss = 0.10170128040107365\n",
      "[EPOCH 32] Test loss = 0.06258408700521488; Learning loss = 0.10098396881991936\n",
      "[EPOCH 33] Test loss = 0.0618774915835801; Learning loss = 0.10055390271630575\n",
      "[EPOCH 34] Test loss = 0.06118468028970944; Learning loss = 0.0994976052152492\n",
      "[EPOCH 35] Test loss = 0.06053111962914144; Learning loss = 0.10092890461823859\n",
      "[EPOCH 36] Test loss = 0.05986032815915231; Learning loss = 0.09831488434269967\n",
      "[EPOCH 37] Test loss = 0.059201964011056055; Learning loss = 0.09743596693323478\n",
      "[EPOCH 38] Test loss = 0.058553930130674524; Learning loss = 0.09703738842561052\n",
      "[EPOCH 39] Test loss = 0.05794287592224353; Learning loss = 0.09860750950038233\n",
      "[EPOCH 40] Test loss = 0.05731470830823668; Learning loss = 0.09605718685185936\n",
      "[EPOCH 41] Test loss = 0.056697704959751766; Learning loss = 0.09523255971557246\n",
      "[EPOCH 42] Test loss = 0.056110931450712075; Learning loss = 0.09547916485100641\n",
      "[EPOCH 43] Test loss = 0.05551330710357045; Learning loss = 0.09416858173081208\n",
      "[EPOCH 44] Test loss = 0.05492555310140336; Learning loss = 0.0935978698672135\n",
      "[EPOCH 45] Test loss = 0.05437247777358684; Learning loss = 0.09508820549993105\n",
      "[EPOCH 46] Test loss = 0.05380314905153491; Learning loss = 0.09230646722660914\n",
      "[EPOCH 47] Test loss = 0.05326422346679401; Learning loss = 0.09249594944223694\n",
      "[EPOCH 48] Test loss = 0.05274836973468388; Learning loss = 0.09826407556919255\n",
      "[EPOCH 49] Test loss = 0.05220579533142797; Learning loss = 0.0906834852551118\n",
      "[EPOCH 50] Test loss = 0.05169513879589555; Learning loss = 0.09268911951746821\n",
      "[EPOCH 51] Test loss = 0.05116919540203136; Learning loss = 0.09017395403163561\n",
      "[EPOCH 52] Test loss = 0.05067218599885762; Learning loss = 0.08997679980989728\n",
      "[EPOCH 53] Test loss = 0.0501647841821693; Learning loss = 0.0885663701413989\n",
      "[EPOCH 54] Test loss = 0.04966510355625837; Learning loss = 0.08817781803552747\n",
      "[EPOCH 55] Test loss = 0.04917327254935292; Learning loss = 0.08773869173791046\n",
      "[EPOCH 56] Test loss = 0.048698503916140605; Learning loss = 0.0865775921660597\n",
      "[EPOCH 57] Test loss = 0.048222088159915015; Learning loss = 0.08677764469035479\n",
      "[EPOCH 58] Test loss = 0.04775172233615855; Learning loss = 0.08675579864345734\n",
      "[EPOCH 59] Test loss = 0.047286892915813124; Learning loss = 0.08632672287579427\n",
      "[EPOCH 60] Test loss = 0.0468327838484667; Learning loss = 0.08534497262264286\n",
      "[EPOCH 61] Test loss = 0.04638447500507366; Learning loss = 0.0852018764133494\n",
      "[EPOCH 62] Test loss = 0.045942910444699545; Learning loss = 0.0846907791717405\n",
      "[EPOCH 63] Test loss = 0.045509230937123876; Learning loss = 0.08423586169486182\n",
      "[EPOCH 64] Test loss = 0.04508067742191369; Learning loss = 0.08405217439118423\n",
      "[EPOCH 65] Test loss = 0.044661288312518824; Learning loss = 0.08314986463560062\n",
      "[EPOCH 66] Test loss = 0.04424484385296387; Learning loss = 0.08324993292494996\n",
      "[EPOCH 67] Test loss = 0.043836741996295066; Learning loss = 0.08254328170000287\n",
      "[EPOCH 68] Test loss = 0.04344889432863037; Learning loss = 0.08591117377148665\n",
      "[EPOCH 69] Test loss = 0.043054023438256164; Learning loss = 0.0816795503484572\n",
      "[EPOCH 70] Test loss = 0.04266410696922906; Learning loss = 0.08159547970413059\n",
      "[EPOCH 71] Test loss = 0.042279172092386436; Learning loss = 0.08129251454034947\n",
      "[EPOCH 72] Test loss = 0.04189986132295813; Learning loss = 0.08094686632043803\n",
      "[EPOCH 73] Test loss = 0.04152694716010856; Learning loss = 0.08057557622090514\n",
      "[EPOCH 74] Test loss = 0.04115955149485254; Learning loss = 0.07991982257937147\n",
      "[EPOCH 75] Test loss = 0.04091391465443751; Learning loss = 0.3297352464110902\n",
      "[EPOCH 76] Test loss = 0.040554948222422074; Learning loss = 0.0795999508792801\n",
      "[EPOCH 77] Test loss = 0.04020111451506511; Learning loss = 0.07921356367818333\n",
      "[EPOCH 78] Test loss = 0.03986674679946918; Learning loss = 0.08019849559682037\n",
      "[EPOCH 79] Test loss = 0.039525195304801995; Learning loss = 0.07834224995402596\n",
      "[EPOCH 80] Test loss = 0.039188211839786415; Learning loss = 0.07813318552973451\n",
      "[EPOCH 81] Test loss = 0.03885890792424273; Learning loss = 0.07744925822252657\n",
      "[EPOCH 82] Test loss = 0.03853738639730147; Learning loss = 0.07662584510204071\n",
      "[EPOCH 83] Test loss = 0.03821490956203552; Learning loss = 0.07715395111793255\n",
      "[EPOCH 84] Test loss = 0.037897408986176974; Learning loss = 0.07676494318775472\n",
      "[EPOCH 85] Test loss = 0.03758477608897258; Learning loss = 0.07638267500118887\n",
      "[EPOCH 86] Test loss = 0.037274587958969894; Learning loss = 0.07642945926976108\n",
      "[EPOCH 87] Test loss = 0.03696930315348478; Learning loss = 0.0761436964178777\n",
      "[EPOCH 88] Test loss = 0.036668176896464816; Learning loss = 0.07593288278690931\n",
      "[EPOCH 89] Test loss = 0.03637318736275109; Learning loss = 0.0752076774464061\n",
      "[EPOCH 90] Test loss = 0.03608064236305613; Learning loss = 0.07513495787224446\n",
      "[EPOCH 91] Test loss = 0.03580952652385509; Learning loss = 0.0778525258926023\n",
      "[EPOCH 92] Test loss = 0.03553895648776398; Learning loss = 0.0758933483257766\n",
      "[EPOCH 93] Test loss = 0.035257721762857276; Learning loss = 0.0743808986073061\n",
      "[EPOCH 94] Test loss = 0.034981948681045275; Learning loss = 0.07401829069941157\n",
      "[EPOCH 95] Test loss = 0.0347121853716836; Learning loss = 0.07345349393189213\n",
      "[EPOCH 96] Test loss = 0.03444394640930965; Learning loss = 0.07349698376664557\n",
      "[EPOCH 97] Test loss = 0.03417969488499335; Learning loss = 0.07316402964693883\n",
      "[EPOCH 98] Test loss = 0.033918137543675314; Learning loss = 0.07309945246180057\n",
      "[EPOCH 99] Test loss = 0.033658740306566085; Learning loss = 0.07320251957655993\n",
      "[EPOCH 100] Test loss = 0.03340520763028411; Learning loss = 0.07241524896056081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100-element Vector{Any}:\n",
       " (0.09115090128485129, 0.36622094991460613)\n",
       " (0.08996068890482693, 0.12789663877393945)\n",
       " (0.08879031412510979, 0.12616387326311368)\n",
       " (0.08773026700433703, 0.13160330548186927)\n",
       " (0.08660407769125822, 0.12386653155873917)\n",
       " (0.08549004086443723, 0.12319099666359097)\n",
       " (0.084395124276685, 0.1217722164031519)\n",
       " (0.08331770844748844, 0.12130304122333724)\n",
       " (0.08249443308389146, 0.359613902919245)\n",
       " (0.08148651740749703, 0.12060151198609792)\n",
       " (0.08046633044511818, 0.11742473502247211)\n",
       " (0.07945410223579516, 0.11719448224807334)\n",
       " (0.07849522906683117, 0.11774815231376226)\n",
       " ⋮\n",
       " (0.03637318736275109, 0.0752076774464061)\n",
       " (0.03608064236305613, 0.07513495787224446)\n",
       " (0.03580952652385509, 0.0778525258926023)\n",
       " (0.03553895648776398, 0.0758933483257766)\n",
       " (0.035257721762857276, 0.0743808986073061)\n",
       " (0.034981948681045275, 0.07401829069941157)\n",
       " (0.0347121853716836, 0.07345349393189213)\n",
       " (0.03444394640930965, 0.07349698376664557)\n",
       " (0.03417969488499335, 0.07316402964693883)\n",
       " (0.033918137543675314, 0.07309945246180057)\n",
       " (0.033658740306566085, 0.07320251957655993)\n",
       " (0.03340520763028411, 0.07241524896056081)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train!(model, optimizer, 100, X_train, Y_train, X_test, Y_test; batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f5a4ba1-3a1c-457d-b6b9-64a61037634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 1] Test loss = 2898.7261576139977; Learning loss = 1898.3024060599212\n",
      "[EPOCH 2] Test loss = 2897.570217054804; Learning loss = 1897.4713907880941\n",
      "[EPOCH 3] Test loss = 2896.2462608800165; Learning loss = 1896.6044309261026\n",
      "[EPOCH 4] Test loss = 2895.266866953088; Learning loss = 1895.7387527228016\n",
      "[EPOCH 5] Test loss = 2894.4463311011523; Learning loss = 1895.0139316121947\n",
      "[EPOCH 6] Test loss = 2893.7832973876884; Learning loss = 1894.4073170505703\n",
      "[EPOCH 7] Test loss = 2893.2564349492354; Learning loss = 1893.9175424277655\n",
      "[EPOCH 8] Test loss = 2892.8390385339912; Learning loss = 1893.5285897237595\n",
      "[EPOCH 9] Test loss = 2892.506611157282; Learning loss = 1893.2205808570004\n",
      "[EPOCH 10] Test loss = 2892.239288822548; Learning loss = 1892.9753447674416\n",
      "[EPOCH 11] Test loss = 2892.02182659023; Learning loss = 1892.7781756555844\n",
      "[EPOCH 12] Test loss = 2891.8427875554125; Learning loss = 1892.6178013993924\n",
      "[EPOCH 13] Test loss = 2891.6936448340207; Learning loss = 1892.485772762981\n",
      "[EPOCH 14] Test loss = 2891.5680232711547; Learning loss = 1892.375794166829\n",
      "[EPOCH 15] Test loss = 2891.46112152174; Learning loss = 1892.2831607749883\n",
      "[EPOCH 16] Test loss = 2891.369287979468; Learning loss = 1892.2043303691564\n",
      "[EPOCH 17] Test loss = 2891.289716059221; Learning loss = 1892.1366096047484\n",
      "[EPOCH 18] Test loss = 2891.220224292011; Learning loss = 1892.0779287780872\n",
      "[EPOCH 19] Test loss = 2891.1590991744515; Learning loss = 1892.0266793881\n",
      "[EPOCH 20] Test loss = 2891.104980613569; Learning loss = 1891.9815981084212\n",
      "[EPOCH 21] Test loss = 2891.0567780116735; Learning loss = 1891.941682243543\n",
      "[EPOCH 22] Test loss = 2891.013609006696; Learning loss = 1891.9061278163933\n",
      "[EPOCH 23] Test loss = 2890.974753043781; Learning loss = 1891.8742843794903\n",
      "[EPOCH 24] Test loss = 2890.939617354237; Learning loss = 1891.8456207753131\n",
      "[EPOCH 25] Test loss = 2890.907709916439; Learning loss = 1891.8197000515775\n",
      "[EPOCH 26] Test loss = 2890.878619800619; Learning loss = 1891.796159523613\n",
      "[EPOCH 27] Test loss = 2890.8520013308394; Learning loss = 1891.7746962880556\n",
      "[EPOCH 28] Test loss = 2890.8275618789776; Learning loss = 1891.7550555472776\n",
      "[EPOCH 29] Test loss = 2890.8050521837963; Learning loss = 1891.73702161231\n",
      "[EPOCH 30] Test loss = 2890.7842590151195; Learning loss = 1891.720410765585\n",
      "[EPOCH 31] Test loss = 2890.7649985361963; Learning loss = 1891.7050658532094\n",
      "[EPOCH 32] Test loss = 2890.747111978412; Learning loss = 1891.690851387063\n",
      "[EPOCH 33] Test loss = 2890.7304612036623; Learning loss = 1891.6776503546946\n",
      "[EPOCH 34] Test loss = 2890.714925844508; Learning loss = 1891.6653609414223\n",
      "[EPOCH 35] Test loss = 2890.700400216501; Learning loss = 1891.6538944218141\n",
      "[EPOCH 36] Test loss = 2890.6867914311956; Learning loss = 1891.6431728807288\n",
      "[EPOCH 37] Test loss = 2890.674017381454; Learning loss = 1891.6331278252605\n",
      "[EPOCH 38] Test loss = 2890.6620054082337; Learning loss = 1891.6236986996137\n",
      "[EPOCH 39] Test loss = 2890.6506909280242; Learning loss = 1891.614831908111\n",
      "[EPOCH 40] Test loss = 2890.6400162890786; Learning loss = 1891.606479803575\n",
      "[EPOCH 41] Test loss = 2890.6299299257375; Learning loss = 1891.5985998495876\n",
      "[EPOCH 42] Test loss = 2890.6203856225115; Learning loss = 1891.591153997102\n",
      "[EPOCH 43] Test loss = 2890.611341800968; Learning loss = 1891.5841081426536\n",
      "[EPOCH 44] Test loss = 2890.6027609803614; Learning loss = 1891.5774316050413\n",
      "[EPOCH 45] Test loss = 2890.594609211481; Learning loss = 1891.5710967259715\n",
      "[EPOCH 46] Test loss = 2890.586855791676; Learning loss = 1891.5650784541647\n",
      "[EPOCH 47] Test loss = 2890.579472882149; Learning loss = 1891.5593541336002\n",
      "[EPOCH 48] Test loss = 2890.572435081314; Learning loss = 1891.5539032231943\n",
      "[EPOCH 49] Test loss = 2890.565719232494; Learning loss = 1891.5487069791054\n",
      "[EPOCH 50] Test loss = 2890.559304273877; Learning loss = 1891.5437483151425\n",
      "[EPOCH 51] Test loss = 2890.5531707663135; Learning loss = 1891.539011691293\n",
      "[EPOCH 52] Test loss = 2890.5473009063576; Learning loss = 1891.5344827643087\n",
      "[EPOCH 53] Test loss = 2890.5416785123484; Learning loss = 1891.53014839841\n",
      "[EPOCH 54] Test loss = 2890.536288461868; Learning loss = 1891.5259966547699\n",
      "[EPOCH 55] Test loss = 2890.531117031047; Learning loss = 1891.5220163759523\n",
      "[EPOCH 56] Test loss = 2890.5261513757973; Learning loss = 1891.51819743636\n",
      "[EPOCH 57] Test loss = 2890.5213797219167; Learning loss = 1891.5145303593654\n",
      "[EPOCH 58] Test loss = 2890.5167911045014; Learning loss = 1891.5110064579449\n",
      "[EPOCH 59] Test loss = 2890.5123754144156; Learning loss = 1891.5076176424795\n",
      "[EPOCH 60] Test loss = 2890.508123276229; Learning loss = 1891.5043564541345\n",
      "[EPOCH 61] Test loss = 2890.504025888341; Learning loss = 1891.5012159757807\n",
      "[EPOCH 62] Test loss = 2890.5000751920434; Learning loss = 1891.4981897134576\n",
      "[EPOCH 63] Test loss = 2890.4962635196384; Learning loss = 1891.495271721236\n",
      "[EPOCH 64] Test loss = 2890.492583829282; Learning loss = 1891.4924563420175\n",
      "[EPOCH 65] Test loss = 2890.489029482768; Learning loss = 1891.4897383799064\n",
      "[EPOCH 66] Test loss = 2890.48559432337; Learning loss = 1891.4871129371493\n",
      "[EPOCH 67] Test loss = 2890.4822725882304; Learning loss = 1891.4845754708522\n",
      "[EPOCH 68] Test loss = 2890.479058827198; Learning loss = 1891.4821217291853\n",
      "[EPOCH 69] Test loss = 2890.4759479767163; Learning loss = 1891.4797476904687\n",
      "[EPOCH 70] Test loss = 2890.472935255881; Learning loss = 1891.4774496188645\n",
      "[EPOCH 71] Test loss = 2890.4700161437404; Learning loss = 1891.4752239862771\n",
      "[EPOCH 72] Test loss = 2890.4671864437923; Learning loss = 1891.4730674569928\n",
      "[EPOCH 73] Test loss = 2890.464442220409; Learning loss = 1891.4709769343633\n",
      "[EPOCH 74] Test loss = 2890.4617796986504; Learning loss = 1891.4689495144687\n",
      "[EPOCH 75] Test loss = 2890.4591953202544; Learning loss = 1891.4669824116631\n",
      "[EPOCH 76] Test loss = 2890.4566857956206; Learning loss = 1891.465073000196\n",
      "[EPOCH 77] Test loss = 2890.4542479798483; Learning loss = 1891.4632188526718\n",
      "[EPOCH 78] Test loss = 2890.4518788904757; Learning loss = 1891.4614176482694\n",
      "[EPOCH 79] Test loss = 2890.4495756846104; Learning loss = 1891.4596671862614\n",
      "[EPOCH 80] Test loss = 2890.447335742661; Learning loss = 1891.4579653685223\n",
      "[EPOCH 81] Test loss = 2890.4451565054596; Learning loss = 1891.4563102620427\n",
      "[EPOCH 82] Test loss = 2890.4430355855966; Learning loss = 1891.4546999781085\n",
      "[EPOCH 83] Test loss = 2890.4409707627415; Learning loss = 1891.4531327547406\n",
      "[EPOCH 84] Test loss = 2890.438959795798; Learning loss = 1891.4516069536307\n",
      "[EPOCH 85] Test loss = 2890.4370006788213; Learning loss = 1891.4501209206467\n",
      "[EPOCH 86] Test loss = 2890.4350914767356; Learning loss = 1891.4486731753789\n",
      "[EPOCH 87] Test loss = 2890.4332303716237; Learning loss = 1891.4472622896308\n",
      "[EPOCH 88] Test loss = 2890.431415541767; Learning loss = 1891.4458869218527\n",
      "[EPOCH 89] Test loss = 2890.429645322202; Learning loss = 1891.4445457272852\n",
      "[EPOCH 90] Test loss = 2890.427918150969; Learning loss = 1891.4432374772891\n",
      "[EPOCH 91] Test loss = 2890.4262324787956; Learning loss = 1891.4419610189868\n",
      "[EPOCH 92] Test loss = 2890.4245868700705; Learning loss = 1891.440715208655\n",
      "[EPOCH 93] Test loss = 2890.4229798858455; Learning loss = 1891.4394989866325\n",
      "[EPOCH 94] Test loss = 2890.4214102566516; Learning loss = 1891.4383112913285\n",
      "[EPOCH 95] Test loss = 2890.4198767067674; Learning loss = 1891.4371511850334\n",
      "[EPOCH 96] Test loss = 2890.4183780236376; Learning loss = 1891.4360177266901\n",
      "[EPOCH 97] Test loss = 2890.4169130486425; Learning loss = 1891.4349100207378\n",
      "[EPOCH 98] Test loss = 2890.4154806922347; Learning loss = 1891.433827212238\n",
      "[EPOCH 99] Test loss = 2890.414079862332; Learning loss = 1891.4327684966502\n",
      "[EPOCH 100] Test loss = 2890.4127095782655; Learning loss = 1891.4317330679082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100-element Vector{Any}:\n",
       " (2898.7261576139977, 1898.3024060599212)\n",
       " (2897.570217054804, 1897.4713907880941)\n",
       " (2896.2462608800165, 1896.6044309261026)\n",
       " (2895.266866953088, 1895.7387527228016)\n",
       " (2894.4463311011523, 1895.0139316121947)\n",
       " (2893.7832973876884, 1894.4073170505703)\n",
       " (2893.2564349492354, 1893.9175424277655)\n",
       " (2892.8390385339912, 1893.5285897237595)\n",
       " (2892.506611157282, 1893.2205808570004)\n",
       " (2892.239288822548, 1892.9753447674416)\n",
       " (2892.02182659023, 1892.7781756555844)\n",
       " (2891.8427875554125, 1892.6178013993924)\n",
       " (2891.6936448340207, 1892.485772762981)\n",
       " ⋮\n",
       " (2890.429645322202, 1891.4445457272852)\n",
       " (2890.427918150969, 1891.4432374772891)\n",
       " (2890.4262324787956, 1891.4419610189868)\n",
       " (2890.4245868700705, 1891.440715208655)\n",
       " (2890.4229798858455, 1891.4394989866325)\n",
       " (2890.4214102566516, 1891.4383112913285)\n",
       " (2890.4198767067674, 1891.4371511850334)\n",
       " (2890.4183780236376, 1891.4360177266901)\n",
       " (2890.4169130486425, 1891.4349100207378)\n",
       " (2890.4154806922347, 1891.433827212238)\n",
       " (2890.414079862332, 1891.4327684966502)\n",
       " (2890.4127095782655, 1891.4317330679082)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = load_dataset(:area)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y, 0.8)\n",
    "\n",
    "area_model = create_model(regression, [\n",
    "    BlueprintLinear(12, 5, method_xavier_normal),\n",
    "    BlueprintActivation(method_sigmoid),\n",
    "    BlueprintLinear(5, 3, method_xavier_normal),\n",
    "    BlueprintActivation(method_sigmoid),\n",
    "    BlueprintLinear(3, 1, method_xavier_normal),\n",
    "    BlueprintActivation(method_sigmoid)\n",
    "])\n",
    "\n",
    "optimizer = OptimizerSGD(learning_rate=0.05)\n",
    "\n",
    "train!(area_model, optimizer, 100, X_train, Y_train, X_test, Y_test; batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.0",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
